{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of\n",
    "hand-written digits.\n",
    "\n",
    "This example is commented in the\n",
    ":ref:`tutorial section of the user manual <introduction>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf6hG7vzmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fba6278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10533f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
